{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9TPKY4uKxzUt5Qix6tl3e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BehrangEbrahimi13/Repo_Paper_01/blob/imputation_methods/Paper_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "lH7r2TioTLMA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Null Generation for a Dataset"
      ],
      "metadata": {
        "id": "cVX43SalTOlI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def generate_random_array(shape, low, high, round, seed=None, as_dataframe=False):\n",
        "    np.random.seed(seed)\n",
        "    random_array = np.random.uniform(low, high, size=(shape)).round(round)\n",
        "    if as_dataframe:\n",
        "        return pd.DataFrame(random_array)\n",
        "    return random_array\n",
        "\n",
        "def generate_random_nulls(dataset, percentage, seed=None, as_dataframe=False):\n",
        "    temp = dataset.copy()\n",
        "    np.random.seed(seed)\n",
        "    null_mask_indices = np.random.choice(range(temp.size), size=int(temp.size * percentage), replace=False)\n",
        "    if as_dataframe:\n",
        "        df_null_mask = pd.DataFrame(False, index=temp.index, columns=temp.columns)\n",
        "        df_null_mask.values.flat[null_mask_indices] = True\n",
        "        df_masked = temp.where(~df_null_mask)\n",
        "        return df_masked\n",
        "    temp.ravel()[null_mask_indices] = np.nan\n",
        "    return temp"
      ],
      "metadata": {
        "id": "YziyJ6QCTRaC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module 1 : PMIC\n",
        "Generally, feature selection does not work on missing data, so imputation is needed beforehand. However, considering irrelevant features severely affect imputation, we use MIC to select features on missing data by ‘‘partial sample strategy’’ (PSS), which is called **PMIC**. ‘‘Partial sample strategy’’ means using the available values of all feature variables and class variable to calculate MIC"
      ],
      "metadata": {
        "id": "fLdXDn2-Iz-E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HuUmBs5TWXZ"
      },
      "outputs": [],
      "source": [
        "!pip install minepy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from minepy import MINE\n",
        "\n",
        "mine = MINE()\n",
        "def pmic_feature_selection(F, C, m):\n",
        "    num_features = F.shape[1]\n",
        "    pmic_scores = np.zeros(num_features)\n",
        "\n",
        "    for i in range(num_features):\n",
        "        musk = ~np.isnan(F[:, i])\n",
        "        # Select column i without null values\n",
        "        feature_without_null = F[musk, i]\n",
        "\n",
        "        # Filter y based on non-null values in column i\n",
        "        class_without_null = C[musk]\n",
        "\n",
        "        # Calculate the MIC (Maximal Information Coefficient) score for the current feature and class\n",
        "        mine.compute_score(feature_without_null, class_without_null)\n",
        "        pmic_scores[i] = mine.mic()\n",
        "\n",
        "    # Sort the indices of pmic_scores in descending order and select the top m indices\n",
        "    top_m_features_idx = np.argsort(pmic_scores)[::-1][:m]\n",
        "    return top_m_features_idx"
      ],
      "metadata": {
        "id": "TGdIK_9NJzcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example Module 1 with Functions"
      ],
      "metadata": {
        "id": "KaGBfJPWrGVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 48\n",
        "percentage = 0.5\n",
        "select_top = 3\n",
        "row = 5\n",
        "\n",
        "# Generate a random 5x4 array with one-digit random values (0-9)\n",
        "X = generate_random_array(shape=(row, 4), low=0, high=10, round=0, seed=seed, as_dataframe=False)\n",
        "print(\"complete X : \\n\", X)\n",
        "\n",
        "# Generate a random 5x1 array with one-digit random values (0-9)\n",
        "Y = generate_random_array((row,), 0, 10, 0, seed=48, as_dataframe=False)\n",
        "print(\"\\ny: \\n\", Y)\n",
        "\n",
        "X_with_null = generate_random_nulls(dataset=X, percentage=percentage, seed=seed, as_dataframe=False)\n",
        "selected_idx = pmic_feature_selection(X_with_null, Y, select_top)\n",
        "selected_features = X_with_null[:, selected_idx]\n",
        "\n",
        "print(\"\\nX_with_null: \\n\", X_with_null)\n",
        "print(f\"\\nSelected {select_top} indices of features ({percentage * 100} percent null):\\n\", selected_idx)\n",
        "print(f\"\\nSelected {select_top} features ({percentage * 100} percent null):\\n\", selected_features)"
      ],
      "metadata": {
        "id": "A3gBqNfbih7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module 2 : Imputation for the missing data"
      ],
      "metadata": {
        "id": "aqh3Unrhrexe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-negative Latent Factor\n",
        "\n",
        "Description:\n",
        "*   R: Incomplete data matrix of shape (n, m).\n",
        "*   d: Rank of the non-negative latent factors.\n",
        "*   lambda1, lambda2: Regularization parameters.\n",
        "*   max_iter: Maximum number of iterations.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_QSlsNoFtwkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def Imputes_the_missing_values_By_non_negative_latent_factor(R, d, lambda1, lambda2, max_iter):\n",
        "    # Initialize non-negative matrix P randomly\n",
        "    n, m = R.shape\n",
        "    R_copy = np.copy(R)\n",
        "    P = np.random.rand(n, d)\n",
        "\n",
        "    # Initialize non-negative matrix Q randomly\n",
        "    Q = np.random.rand(d, m)\n",
        "\n",
        "    # Initialize I according to (17)\n",
        "    I = np.ones((n, m))\n",
        "    R_nan_mask = np.isnan(R_copy)\n",
        "    I[R_nan_mask] = 0\n",
        "\n",
        "    # Set zero for Null\n",
        "    R_copy[R_nan_mask] = 0\n",
        "\n",
        "    # Initialize iteration counter\n",
        "    iter = 0\n",
        "\n",
        "    # Convergence criterion\n",
        "    converge = False\n",
        "\n",
        "    while not converge and iter < max_iter:\n",
        "        # Update P according to (22)\n",
        "        P_new = P * ((I * R_copy) @ Q.T) / ((I * (P @ Q)) @ Q.T + lambda1 * P)\n",
        "\n",
        "        # Update Q according to (23)\n",
        "        Q_new = Q * (P_new.T @ (I * R_copy)) / (P_new.T @ (I * (P_new @ Q)) + lambda2 * Q)\n",
        "\n",
        "        # Check convergence\n",
        "        if np.allclose(P, P_new) and np.allclose(Q, Q_new):\n",
        "            converge = True\n",
        "\n",
        "        # Update P and Q\n",
        "        P = P_new\n",
        "        Q = Q_new\n",
        "\n",
        "        # Increment iteration counter\n",
        "        iter += 1\n",
        "\n",
        "    # Impute R by (11) and obtain R_cpl\n",
        "    PQ = np.round( P @ Q, decimals=3)\n",
        "    R_cpl = np.where(R_nan_mask, PQ, R)\n",
        "\n",
        "    return R_cpl\n"
      ],
      "metadata": {
        "id": "gMXdVUfztlRl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperimpute"
      ],
      "metadata": {
        "id": "cbDeRI_665k3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hyperimpute"
      ],
      "metadata": {
        "id": "JGuFnGw4664W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from hyperimpute.plugins.imputers import Imputers\n",
        "imputers = Imputers()\n",
        "\n",
        "X = pd.DataFrame([[1, 4, 7, 10], [4, 7, np.nan, np.nan], [3, 6, 9, 12], [8, 11, 14, 17]])\n",
        "\n",
        "method = \"gain\"\n",
        "\n",
        "plugin = Imputers().get(method)\n",
        "out = plugin.fit_transform(X.copy()).round(2)\n",
        "\n",
        "print(method, out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8Dcu9uw7OUP",
        "outputId": "61580f22-99c2-400d-e8b7-66c8c1130de1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gain      0     1     2      3\n",
            "0  1.0   4.0   7.0  10.00\n",
            "1  4.0   7.0  10.3  13.45\n",
            "2  3.0   6.0   9.0  12.00\n",
            "3  8.0  11.0  14.0  17.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example Module 2 Non-negative Latent Factor and GAIN with Functions"
      ],
      "metadata": {
        "id": "ETgB4s0O3RNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 48\n",
        "round = 2\n",
        "percentage = 0.3\n",
        "row = 5\n",
        "\n",
        "# Generate a random 5x4 array with one-digit random values (0-9)\n",
        "X = generate_random_array(shape=(row, 4), low=0, high=10, round=round, seed=seed, as_dataframe=False)\n",
        "print(\"complete X : \\n\", X)\n",
        "\n",
        "X_with_null = generate_random_nulls(dataset=X, percentage=percentage, seed=seed, as_dataframe=False)\n",
        "print(\"\\nX_with_null : \\n\", X_with_null)\n",
        "\n",
        "R = np.copy(X_with_null)\n",
        "d = 2\n",
        "lambda1 = 0.1\n",
        "lambda2 = 0.2\n",
        "max_iter = 100\n",
        "\n",
        "# Code execution\n",
        "R_cpl = Imputes_the_missing_values_By_non_negative_latent_factor(R, d, lambda1, lambda2, max_iter)\n",
        "print(\"\\nComplete data after imputation by non_negative_latent_factor: \\n\", R_cpl)\n",
        "\n",
        "\n",
        "method = \"gain\"\n",
        "plugin = Imputers().get(method)\n",
        "out = plugin.fit_transform(R.copy()).round(round)\n",
        "\n",
        "print(f'\\nComplete data after imputation by {method}: \\n', out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xp9A-zBe5Lbs",
        "outputId": "248beabf-e739-4616-b928-cd9ff7aad797"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "complete X : \n",
            " [[0.17 8.92 2.85 2.99]\n",
            " [7.92 3.24 8.65 4.48]\n",
            " [5.48 3.57 1.12 1.42]\n",
            " [4.45 7.32 4.6  5.93]\n",
            " [3.37 4.54 1.87 4.09]]\n",
            "\n",
            "X_with_null : \n",
            " [[0.17  nan 2.85 2.99]\n",
            " [7.92  nan 8.65  nan]\n",
            " [ nan  nan 1.12 1.42]\n",
            " [ nan 7.32 4.6  5.93]\n",
            " [3.37 4.54 1.87 4.09]]\n",
            "\n",
            "Complete data after imputation by non_negative_latent_factor: \n",
            " [[ 0.17   0.235  2.85   2.99 ]\n",
            " [ 7.92   9.428  8.65  10.738]\n",
            " [ 0.906  1.078  1.12   1.42 ]\n",
            " [ 5.593  7.32   4.6    5.93 ]\n",
            " [ 3.37   4.54   1.87   4.09 ]]\n",
            "\n",
            "Complete data after imputation by gain: \n",
            "       0     1     2     3\n",
            "0  0.17  4.57  2.85  2.99\n",
            "1  7.92  5.84  8.65  4.05\n",
            "2  1.29  4.57  1.12  1.42\n",
            "3  3.75  7.32  4.60  5.93\n",
            "4  3.37  4.54  1.87  4.09\n"
          ]
        }
      ]
    }
  ]
}